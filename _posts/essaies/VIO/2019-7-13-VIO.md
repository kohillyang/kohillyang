---
layout: post
title: Notes of VIO
date: 2019-7-13 19:40
comments: true 
external-url:
categories: linux
permalink: /vio
---
<br>
### Several Tips

基于滤波的方法：

MSCKF（2007）, VIO很经典的一篇论文

ROVIO, 光度误差/重投影误差

Stereo-MSCKF 开源的MSCKF（2018）

基于优化的VIO：
OKVIS 最早基于优化的VIO系统（开源）
TRO， SVO+预积分，预积分公式非常细致，复现论文Learn-VIO-ORB
VINS-Mono


### 论文阅读 Is Levenberg-Marquardt the Most Efficient Optimization Algorithm for Implementing Bundle Adjustment? 

论文链接 <https://projects.ics.forth.gr/_publications/0201-P0401-lourakis-levenberg.pdf>


非线性最小二乘
--------------

对于一个最小二乘问题,注意$\mathbf{W}$为对称矩阵： 

$$\begin{aligned}
    \mathop{min} \mathbf{F}(x) &= \mathbf{f}^{T}(x)\mathbf{W}\mathbf{f}(x)\\
    \mathbf{f}(x+h) &\simeq \mathbf{f}(x) + \mathbf{J}\mathbf{h}\\
    F(x+h) &= \frac{1}{2}f(x+h)^{T}Wf(x+h) \simeq L(h) \\
    L(h) &= \frac{1}{2}(\mathbf{f}(x) + \mathbf{J}\mathbf{h}) ^ T W (\mathbf{f}(x) + \mathbf{J}\mathbf{h})\\     &= \frac{1}{2} \left[  f^T(x)Wf(x)  + 2h^TJ^TW(x)f(x) + h^TJ^TWJh  \right] \\
     &= \frac{1}{2} \left[  F(x)  + 2h^Tg + h^THh  \right] \\
     -L(0)+L(h) &= h^Tg + \frac{1}{2}h^THh \\
     -L(0)+L(h_{gn}) &= h_{gn}^Tg + \frac{1}{2}h_{gn}^THh_{gn} \\
                    &= \frac{1}{2} h_{gn}^Tg\end{aligned}$$

增益系数 

$$\begin{aligned}
    \rho &= \frac{F(x+h)-F(x)}{L(h)-L(0)}\\
        &= \frac{F(x+h)-F(x)}{h^Tg + \frac{1}{2}h^THh}\end{aligned}$$

$L(h)$对$h$的一阶导和二阶导为： 

$$\begin{aligned}
    L'(x) = g(x) &= \frac{dL(h)}{dh} = J^TWf(x)+ h^TJ^TWJ\\
    H(x) &= \frac{d^2L(h)}{dh^2} = J^TWJ\end{aligned}$$

令一阶导等于0，可以得到正规方程(normal equation)： 

$$J^TWJh = -J^TWf(x)$$

LM(Dampled Gauss-Newton method, Levenberg-Marquardt Method),正规方程变为： 

$$(J^TWJ + \lambda \mathbf{I})h_{lm} = -J^TWf(x)$$

当阻尼系数$\lambda$比较大的时候，上式趋近于梯度下降法，当$\lambda$趋近于0时，上式趋近于高斯牛顿法

参考论文：

```bash
1. The Levenberg-Marquardt method for nonlinear least squares curve-fitting problems
2. Is Levenberg-Marquardt the Most Efficient Optimization Algorithm for
Implementing Bundle Adjustment?
3. METHODS FOR NON-LINEAR LEAST SQUARES PROBLEMS.
其中1介绍了3中LM中的阻尼因子的更新方法，2对比了在SLAM问题中，Dogleg与LM的精度，结果Dogleg稍好于LM，3详细介绍了Dogleg与LM算法。
```

### 3D地表重建主流框架
`1`. Colmap(开源， 需要cuda)<br>
`2`. OpenDroneMap（开源）<br>
`3`. Altizure(OpenDroneMap（开源）)

Steps of 3D reconstruction by ODM(from <https://community.opendronemap.org/t/where-can-i-find-background-information-on-the-concepts-of-odm/665/2>).

```
In short, the steps are:

    1. Images metadata extraction (GPS location, coordinate system)
    2. Structure from motion (from images to camera positions/orientations and sparse point cloud). We use OpenSfM for this.
    3. Multi view stereo (from camera + images to dense point clouds)
    4. Meshing (from points clouds to triangle meshes, we use mostly a Poisson Reconstruction approach but have support for 2.5D meshing as well)
    5. Texturing (from camera + images + meshes to textured meshes)
    6. Georeferencing (from local coordinates + GPS and/or ground control points to real world coordinates)
    7. DSM/DTM (from real world points to elevation models)
    8. Orthophoto generation (from textured meshes in real world coordinates to GeoTIFF)
```

### 舒尔补

对于任意的矩阵块$\mathbf{M}$: $$\mathbf{M}=\left[\begin{array}{ll}
        {\mathbf{A}} & {\mathbf{B}} \\
        {\mathbf{C}} & {\mathbf{D}}
        \end{array}\right]$$
如果矩阵块$\mathbf{D}$可逆，则$\mathbf{A}-\mathbf{B D}^{-1} \mathbf{C}$称为$\mathbf{D}$关于$\mathbf{M}$的舒尔补。
如果矩阵块$\mathbf{A}$可逆，则$\mathbf{D}-\mathbf{C A}^{-1} \mathbf{B}$称为$\mathbf{D}$关于$\mathbf{M}$的舒尔补。

### SLAM问题的稀疏性

某一时刻，VIO的状态集合为相机的位姿$\left\{\mathbf{x}_{\mathbf{p}_j}, 1\leq j\leq m\right\}$，以及特征点的位姿$\left\{\mathbf{x}_{\mathbf{m}_i}, 1\leq i\leq m\right\}$
令 $$\begin{aligned}
    \mathbf{x}=\left[\begin{array}{c}
        {\mathbf{x}_{\mathbf{p}}} \\
        {\mathbf{x}_{\mathbf{m}}}
        \end{array}\right]=\left[\begin{array}{c}
        {\mathbf{x}_{\mathbf{p}_{1}}} \\
        {\vdots} \\
        {\mathbf{x}_{\mathbf{p}_{m}}} \\
        {\mathbf{x}_{\mathbf{m}_{1}}} \\
        {\vdots} \\
        {\mathbf{x}_{\mathbf{m}_{n}}}
        \end{array}\right]    \end{aligned}$$ 并且有：
$$\mathbf{x}_{\mathbf{p}_{j}}=f_{j}\left(\mathbf{x}_{\mathbf{p}_{j-1}}, \mathbf{u}_{j}\right)+\mathbf{w}_{j}$$
上式描述了相邻时刻相机的位姿的约束关系，这个约束关系可以从预积分中得到，亦可以从相机的运动模型中得到。$\mathbf{w}_{j} \sim \mathcal{N}\left(0, \mathbf{Q}_{j}\right)$是高斯白噪声。
当$\mathbf{p}_{j-1}$作为先验时，$\mathbf{x}_{\mathbf{p}_{j}}$服从正态分布，$p\left(\mathbf{x}_{\mathbf{p}}\right)=\mathcal{N}\left(\mu_{\mathbf{p}}, \mathbf{Q}\right)$,
其中 $$\mu_{\mathbf{p}}=f(\mathbf{x})=\left[\begin{array}{c}
    {\mathbf{x}_{\mathbf{p}_{1}}} \\
    {f_{1}\left(\mathbf{x}_{\mathbf{p}_{1}}, \mathbf{u}_{2}\right)} \\
    {\vdots} \\
    {f_{m}\left(\mathbf{x}_{\mathbf{p}_{m-1}}, \mathbf{u}_{m}\right)}
    \end{array}
    \right],     \mathbf{Q}=\left[\begin{array}{ccc}
        {\mathbf{Q}_{1}} & {} & {} \\
        {} & {\ddots} & {} \\
        {} & {} & {\mathbf{Q}_{m}}
        \end{array}\right]$$
另外摄像机，加速度计等传感器会提供一些量测信息：
$$\mathbf{z}_{i j}=h_{i j}\left(\mathbf{x}_{\mathbf{m}_{i}}, \mathbf{x}_{\mathbf{p}_{j}}\right)+\mathbf{v}_{i j}$$
其中$\mathbf{v}_{i j} \sim \mathcal{N}\left(0, \mathbf{R}_{i j}\right)$。
在基于非线性最小二乘的框架中，记：
$$g(\mathbf{x}) = \left[\begin{array}{c}
    {\mathbf{z}-h(\mathbf{x})} \\
    {\mathbf{x}_{\mathbf{p}}-f\left(\mathbf{x}_{\mathbf{p}}\right)}
    \end{array}\right]$$ 优化的目标是使下式最小,
注意$\mathbf{W}$为对称矩阵，即$\mathbf{W}=\mathbf{W}^T$：
$$\ell(\mathbf{x})=\frac{1}{2}\left(g(\mathbf{x})^{T} \mathbf{W} g(\mathbf{x})\right),    
     \mathbf{W}=\left[\begin{array}{ccc}
        {\mathbf{R}^{-1}} & {0} \\
        {0} & {\mathbf{Q}^{-1}}
        \end{array}\right]$$
在高斯牛顿算法的框架下，在每一次迭代时，目标是求解$h$使得下式最小：
$$\ell(\mathbf{x+h})=\frac{1}{2}(g(\mathbf{x)+J_gh})^{T} \mathbf{W}   (g(\mathbf{x)+J_gh}   )$$
其中$\mathbf{J_gh} = \frac{\partial g(\mathbf{x})}{\partial \mathbf{x}}$，
$$\begin{aligned}
    \frac{\partial \ell(\mathbf{x+h})}{\partial \mathbf{x}}&=
    \frac{1}{2} g(\mathbf{x)}^{T}\mathbf{W}g(\mathbf{x)} + 
    g(\mathbf{x)}^{T}\mathbf{W}\mathbf{J_gh} + 
    \frac{1}{2}\mathbf{h}^T{\mathbf{J_g}}^T\mathbf{W}\mathbf{J_gh} \\
    \frac{\partial^2 \ell(\mathbf{x+h})}{\partial \mathbf{x^2}}&=
    \mathbf{{J_g}}^TWg(\mathbf{x}) + {\mathbf{J_g}}^T\mathbf{W}\mathbf{J_gh}\end{aligned}$$
令上式等于$\mathbf{0}$，并令$\mathbf{H}={\mathbf{J_g}}^T\mathbf{W}\mathbf{J_g}$，得到正规方程(Normal
Equation): $$\mathbf{Hh=-\mathbf{{J_g}}^TWg(\mathbf{x})}$$
将$\mathbf{H}$展开： $$\begin{aligned}
    \mathbf{H} &= \begin{bmatrix}
        \mathbf{J_f} \\
        \mathbf{J_h}
    \end{bmatrix} ^T
    \begin{bmatrix}
        \mathbf{R}^{-1} & 0 \\
        0 & \mathbf{Q}^{-1}
    \end{bmatrix} 
    \begin{bmatrix}
        \mathbf{J_f} \\
        \mathbf{J_h}
    \end{bmatrix} \\
    &= \mathbf{J_fR^{-1}J_f} + \mathbf{J_gQ^{-1}J_g} \\
    &= \left[\begin{array}{cc}
        {\mathbf{\Lambda}_{\mathbf{p}}} & {\mathbf{\Lambda}_{\mathbf{p} \mathbf{m}}} \\
        {\mathbf{\Lambda}_{\mathbf{p} \mathbf{m}}^{T}} & {\mathbf{\Lambda}_{\mathbf{m}}}
        \end{array}\right]\end{aligned}$$ 因此正规方程可写成以下的形式：
$$\left[\begin{array}{cc}
    {\mathbf{\Lambda}_{\mathbf{p}}} & {\mathbf{\Lambda}_{\mathbf{p} \mathbf{m}}} \\
    {\mathbf{\Lambda}_{\mathbf{p} \mathbf{m}}^{T}} & {\mathbf{\Lambda}_{\mathbf{m}}}
    \end{array}\right]\left[\begin{array}{c}
    {\delta \mathbf{x}_{\mathbf{p}}} \\
    {\delta \mathbf{x}_{\mathbf{m}}}
    \end{array}\right]=\left[\begin{array}{l}
    {\mathbf{g}_{\mathbf{p}}} \\
    {\mathbf{g}_{\mathbf{m}}}
    \end{array}\right]$$
利用$\mathbf{H}$的性质，可以用舒尔补加速正规方程的求解：
$$\left[\begin{array}{cc}
    {\boldsymbol{\Lambda}_{\mathbf{p}}-\boldsymbol{\Lambda}_{\mathbf{p} \mathbf{m}}\left(\boldsymbol{\Lambda}_{\mathbf{m}}\right)^{-1} \boldsymbol{\Lambda}_{\mathbf{p} \mathbf{m}}^{\mathbf{T}}} & {0} \\
    {\boldsymbol{\Lambda}_{\mathbf{p} \mathbf{m}}^{T}} & {\boldsymbol{\Lambda}_{\mathbf{m}}}
    \end{array}\right]\left[\begin{array}{c}
    {\delta \mathbf{x}_{\mathbf{p}}} \\
    {\delta \mathbf{x}_{\mathbf{m}}}
    \end{array}\right]=\left[\begin{array}{c}
    {\mathbf{g}_{\mathbf{p}}-\boldsymbol{\Lambda}_{\mathbf{p} \mathbf{m}}\left(\boldsymbol{\Lambda}_{\mathbf{m}}\right)^{-\mathbf{1}} \mathbf{g}_{\mathbf{m}}} \\
    {\mathbf{g}_{\mathbf{m}}}
    \end{array}\right]$$ 可以得到： $$\begin{aligned}
    &\delta \mathbf{x}_{\mathbf{p}}=\left(\Lambda_{p}-\mathbf{\Lambda}_{\mathbf{p} \mathbf{m}}\left(\mathbf{\Lambda}_{\mathbf{m}}\right)^{-\mathbf{1}} \mathbf{\Lambda}_{\mathbf{p} \mathbf{m}}^{\mathbf{T}}\right)^{-\mathbf{1}}\left(\mathbf{g}_{\mathbf{p}}-\mathbf{\Lambda}_{\mathbf{p} \mathbf{m}}\left(\mathbf{\Lambda}_{\mathbf{m}}\right)^{-\mathbf{1}} \mathbf{g}_{\mathbf{m}}\right)\\
    &\delta \mathbf{x}_{\mathbf{m}}=\quad\left(\mathbf{\Lambda}_{\mathbf{m}}\right)^{-\mathbf{1}}\left(\mathbf{g}_{\mathbf{m}}-\mathbf{\Lambda}_{\mathbf{p} \mathbf{m}}^{\mathbf{T}} \delta \mathbf{x}_{\mathbf{p}}\right)
    \end{aligned}$$

### 条件概率与边际概率

假设多元变量$x$服从零均值高斯分布,$x$由两部分组成：
$$\mathbf{x}=\begin{bmatrix}
    \mathbf{a} \\
    \mathbf{b}
\end{bmatrix}$$ 变量之间的协方差为： $$\mathbf{K}=\begin{bmatrix}
        \mathbf{A} & \mathbf{C} ^T \\
        \mathbf{C} & \mathbf{D}
    \end{bmatrix}$$
其中$\mathbf{A}=\mathop{cov}(\mathbf{a}, \mathbf{a})$，$\mathbf{D}=\mathop{cov}(\mathbf{b}, \mathbf{b})$,
$\mathbf{C}=\mathop{cov}(\mathbf{a}, \mathbf{b})$，
线性条件下，不妨假设： $$\begin{aligned}
    \mathbf{x}_b&=\mathbf{F}_{ba}\mathbf{x}_a+\tilde{\mathbf{w}} \\
    \mathbf{x}_a&=\tilde{\mathbf{v}}\end{aligned}$$
其中$\tilde{\mathbf{w}}$与$\tilde{\mathbf{v}}$不相关，则有：
$$\begin{aligned}
    \mathop{cov}(\mathbf{a}, \mathbf{a}) &= E(\tilde{\mathbf{v}} \tilde{\mathbf{v}} ^T) = \mathbf{A}\\
    \mathop{cov}(\mathbf{b}, \mathbf{b}) &= \mathbf{F}_{ba}\mathbf{A}\mathbf{F}_{ba}^T + E(\tilde{\mathbf{w}}\tilde{\mathbf{w}}^T) =\mathbf{D}\\
    \mathop{cov}(\mathbf{b}, \mathbf{a}) &=  \mathbf{F}_{ba}\mathbf{A}=\mathbf{C}\end{aligned}$$
从而$\mathbf{F}_{ba}=\mathbf{CA^{-T}}$,$\tilde{\mathbf{w}}=\mathbf{x}_b-\mathbf{CA^{-1}}\mathbf{x}_a$,$E(\tilde{\mathbf{w}}\tilde{\mathbf{w}}^T)=\mathbf{D}-\mathbf{CA^{-T}C^T}$,
于是：
$$P(\mathbf{x}_b | \mathbf{x}_a) \sim \mathcal{N}\left(\mathbf{C} \mathbf{A}^{-T} \mathbf{x}_a, \mathbf{D}-\mathbf{CA^{-T}C^T}\right)$$
从舒尔补分解的角度亦可以导出以上结果，对于任意一个可逆方阵
$$\left[\begin{array}{cc}
    {\mathbf{A}} & {\mathbf{B}} \\
    {\mathbf{C}} & {\mathbf{D}}
    \end{array}\right]^{-1}=\left[\begin{array}{cc}
    {\mathbf{I}} & {-\mathbf{A}^{-1} \mathbf{B}} \\
    {\mathbf{0}} & {\mathbf{I}}
    \end{array}\right]\left[\begin{array}{cc}
    {\mathbf{A}^{-1}} & {\mathbf{0}} \\
    {\mathbf{0}} & {\Delta_{\mathbf{A}}^{-1}}
    \end{array}\right]\left[\begin{array}{rr}
    {\mathbf{I}} & {\mathbf{0}} \\
    {-\mathbf{C A}^{-1}} & {\mathbf{I}}
    \end{array}\right]$$
其中$\Delta_{\mathrm{A}}=\mathbf{D}-\mathbf{C} \mathbf{A}^{-1} \mathbf{B}$,
于是： $$\begin{aligned}
    P(\mathbf{x}_b | \mathbf{x}_a) ·&\propto \exp \left(-\frac{1}{2}\left[\begin{array}{l}
    {a} \\
    {b}
    \end{array}\right]^{\top}\left[\begin{array}{cc}
    {A} & {C^{\top}} \\
    {C} & {D}
    \end{array}\right]^{-1}\left[\begin{array}{l}
    {a} \\
    {b}
    \end{array}\right]\right)\\
    &\propto \exp \left(-\frac{1}{2}\left[\begin{array}{l}
    {a} \\
    {b}
    \end{array}\right]^{\top}\left[\begin{array}{cc}
    {I} & {-A^{-1} C^{\top}} \\
    {0} & {I}
    \end{array}\right]\left[\begin{array}{cc}
    {A^{-1}} & {0} \\
    {0} & {\Delta_{\mathrm{A}}^{-1}}
    \end{array}\right]\left[\begin{array}{cc}
    {I} & {0} \\
    {-C A^{-1}} & {I}
    \end{array}\right]\left[\begin{array}{l}
    {a} \\
    {b}
    \end{array}\right]\right) \\
    &\propto \exp \left(-\frac{1}{2}\left[a^{\top} \quad\left(b-C A^{-1} a\right)^{\top}\right]\left[\begin{array}{cc}
    {A^{-1}} & {0} \\
    {0} & {\Delta_{\mathrm{A}}^{-1}}
    \end{array}\right]\left[\begin{array}{cc}
    {a} & {} \\
    {b-C A^{-1} a}
    \end{array}\right]\right) \\
    &\propto  \underbrace{\exp \left(-\frac{1}{2} a^{\top} A^{-1} a\right)}_{p(a)} \underbrace{\exp \left(-\frac{1}{2}\left(b-C A^{-1} a\right)^{\top} \Delta_{\mathrm{A}}^{-1}\left(b-C A^{-1} a\right)\right)}_{p(b | a)}\end{aligned}$$
于是：
$$P(\mathbf{x}_b | \mathbf{x}_a) \sim \mathcal{N}\left(\mathbf{C} \mathbf{A}^{-1} \mathbf{x}_a, \mathbf{D}-\mathbf{CA^{-1}C^T}\right)$$

c\|c\|c & 边际概率
$p(\boldsymbol{a})=\int p(\boldsymbol{a}, \boldsymbol{b}) d \boldsymbol{b}$
& 条件概率
$p(\boldsymbol{a} | \boldsymbol{b})=p(\boldsymbol{a}, \boldsymbol{b}) / p(\boldsymbol{b})$\
协方差矩阵 & $\begin{array}{l}
        {\mu=\mu_{a}} \\
        {\Sigma=\sum_{a a}}
        \end{array}$ & $\begin{aligned}
            \boldsymbol{\mu}^{\prime}=& \boldsymbol{\mu}_{a}+\Sigma_{a b} \Sigma_{b b}^{-1}\left(\boldsymbol{b}-\boldsymbol{\mu}_{b}\right) \\
            \Sigma^{\prime}=& \Sigma_{a a}-\Sigma_{a b} \Sigma_{b b}^{-1} \Sigma_{b a}
            \end{aligned}$\
信息矩阵 & $\begin{aligned}
        \boldsymbol{\eta} &=\boldsymbol{\eta}_{a}-\Lambda_{a \beta} \Lambda_{b b}^{-1} \boldsymbol{\eta}_{b} \\
        \Lambda &=\Lambda_{a a}-\Lambda_{a b} \Lambda_{b b}^{-1} \Lambda_{b a}
        \end{aligned}$ & $\begin{array}{c}
            {\boldsymbol{\eta}^{\prime}=\boldsymbol{\eta}_{a}-\Lambda_{a b} \boldsymbol{b}} \\
            {\Lambda^{\prime}=\Lambda_{a a}}
            \end{array}$\

[\[tbl:margin\_prob\_cond\_prob\_from\_joint\_prob\]]{#tbl:margin_prob_cond_prob_from_joint_prob
label="tbl:margin_prob_cond_prob_from_joint_prob"}

假设变量$x_a$与$x_b$有：
$$P(\boldsymbol{a}, \boldsymbol{b})=\mathcal{N}\left(\left[\begin{array}{c}
        {\boldsymbol{\mu}_{a}} \\
        {\boldsymbol{\mu}_{b}}
        \end{array}\right],\left[\begin{array}{cc}
        {\boldsymbol{\Sigma}_{a a}} & {\boldsymbol{\Sigma}_{a b}} \\
        {\boldsymbol{\Sigma}_{b a}} & {\boldsymbol{\Sigma}_{b b}}
        \end{array}\right]\right) =\mathcal{N}^{-1}\left(\left[\begin{array}{c}
            {\boldsymbol{\eta}_{a}} \\
            {\boldsymbol{\eta}_{b}}
            \end{array}\right],\left[\begin{array}{cc}
            {\boldsymbol{\Lambda}_{a a}} & {\boldsymbol{\Lambda}_{a a}} \\
            {\boldsymbol{\Lambda}_{b a}} & {\boldsymbol{\Lambda}_{b b}}
            \end{array}\right]\right)$$
在表[\[tbl:margin\_prob\_cond\_prob\_from\_joint\_prob\]](#tbl:margin_prob_cond_prob_from_joint_prob){reference-type="ref"
reference="tbl:margin_prob_cond_prob_from_joint_prob"}中给出了已知联合概率的信息矩阵/协方差矩阵的情况下，边际概率和条件概率的协方差求法。总的来说，条件概率对信息矩阵的操作更为方便，而边际概率对协方差矩阵的操作更为方便。