---
layout: post
title: Openpose 复现笔记
date: 2019-12-30 19:40
comments: true 
external-url:
categories: Deep Learning
permalink: /openpose
---
<br>


### 原始的Python代码有部分代码，修改之后精度高了2个mAP左右：

下面是原始的模型不带Flip，多尺度前传的结果：

```
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.590
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.810
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.643
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = 0.575
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.623
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.630
 Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.824
 Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.675
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = 0.582
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.699
 ```

### 没有mask的复现情况：

```markdown
Our implementation(Without mask)（40 epochs）:
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.532
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.765
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.569
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = 0.515
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.566
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.572
 Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.784
 Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.607
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = 0.526
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.638
 ```

单纯加上mask之后分数几乎没变

将stage改为第一个stage（代码写反了，原模型最后一个stage）（40 epochs）：
```
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.545
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.766
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.588
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = 0.521
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.592
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.584
 Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.789
 Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.620
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = 0.532
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.660
```
其实就表示后面的6个stage对AP的增益很有限

修改尺度缩放策略，之前是单纯随机系数缩放图片，改为根据bbox大小缩放后(24 epochs, 1xlr)：

```
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.560
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.780
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.603
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = 0.542
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.597
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.598
 Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.800
 Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.636
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = 0.551
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.668
```
注意上面的结果只训练了24个epoch，因为接着训练要回滚代码，就暂时放一边。

同样的代码训练VGG19, 22epochs
```
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.546
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.778
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.587
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = 0.541
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.567
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.587
 Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.800
 Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.625
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = 0.552
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.639
```

Todo List:

- Training the network with VGG19 backbone with setting lr_mult and wd_mult.

- Training the network with Dilated-Resnet50 backbone with setting lr_mult and wd_mult.


 ### 代码中一部分细节：

 `1.` 代码中不同层的学习率和weight decay参数都不同，backbone稍微小一些。
 
 `2.` 代码中的数据增强充斥者大量的joints self等，目前只发现是为了在crop之后，在增加mask只根据被crop的person来加mask。（有部分part或者keypoints无法被标注，所以需要mask）,所以按bbox对图片crop之后，会使用bbox_id来生成mask，如果当前bbox的target可见，则不会屏蔽其它人的loss。使用bbox_idx生成mask的代码如下：
 ```python
     def genHeatmapMask(self, joints, heatmaps, bbox_idx):
        mask = np.ones_like(heatmaps)
        for j in range(len(joints[0])):
            if joints[bbox_idx, j, 2] > 0:
                pass
            else:
                mask[j][:] = 0
        return mask

    def genPafmapMask(self, limb_sequence, joints, pafmaps, bbox_idx):
        mask = np.ones_like(pafmaps)
        for j in range(len(limb_sequence)):
            if joints[bbox_idx, limb_sequence[j, 0], 2] > 0 and joints[bbox_idx, limb_sequence[j, 1], 2] > 0:
                pass
            else:
                mask[j][:] = 0
        return mask
```

 `3.` 数据增强有两个mask, mask all和mask miss。目测[原代码中mode 为常量5](https://github.com/CMU-Perceptual-Computing-Lab/caffe_train/blob/76dd9563fb24cb1702d0245cda7cc36ec2aed43b/src/caffe/cpm_data_transformer.cpp#L435)， mode==5的情况下， mask all似乎没用到。而且mode==6的时候mask all的通道会被background channel 覆盖（就很迷）。


 crop之后： mask all，mask miss会在crop的padding区域置零（其他从coco的mask 读到）。

 aug的步骤： Scale->Rotate->Crop->Flip

mask_miss 应该是crowed区域（去掉被标注的区域）和keypoints区域太小的区域的或。


[Updata]: 发现代码中做Random Scale 是根据bbox的scale来做Random Scale的，当bbox的尺度比较大的时候，scale尺度会比较小，and vice versa.

### 关于weight decay
原始CPM网络对于weight的wd_mul为1，bias的为0，mxnet默认对所有层的所有参数都有weight decay，参考帖子<https://discuss.mxnet.io/t/how-to-eliminated-the-weight-decay-on-the-bias-and-batch-nomalization/4661>， 需要增加如下代码：

```python
params = net.collect_params()
for p_name, p in params.items():
    if p_name.endswith(('_bias', '_gamma', '_beta')):
        p.wd_mult = 0
```

在论文<https://arxiv.org/pdf/1807.11205.pdf>中有这样一段话：

In neural network training, it is a typical practice to penalize only the weights of the affine transformation at each layer and
leaves the biases unregularized [11]. What we have observed in our training for AlexNet is that if we also leave two parameter sets
β and γ in batch normalization unregularized, our model could achieve better convergence and usually with less time to train for
the same number of epochs. β and γ are two trainable parameters in batch normalization as shown in below formulas, where µB is
the mean of mini-batch and $\sigma ^2$ is the variance of mini-batch. β and γ contrals the scale and shift of the normalized result.

<img src="{{ site.github_cdn_prefix }}/screenshots/2020-01-14-15-04-28.png" class="img-responsive" style="width:40%;margin-left:2%"/><br>


下面有一张不带weight decay训练和带weight decay训练的对比图，可以看到加了之后训练要更稳定些，精度也要高一些：
<img src="{{ site.github_cdn_prefix }}/screenshots/2020-01-14-15-09-10.png" class="img-responsive" style="width:70%;margin-left:2%"/><br>